{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOJV7YUTyJWV"
      },
      "source": [
        "# Pre-Training/Continous Training Model pada dataset Pubmed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXn7Xr5FyJWf"
      },
      "source": [
        "## Load Data yang sudah di extract sebelumnya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cd8d66e83e934fa2a1d74141e955c931"
          ]
        },
        "id": "oXGjn_NSyJWf",
        "outputId": "3eef0d8e-3686-4712-bdc9-26f4038c0611"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd8d66e83e934fa2a1d74141e955c931",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7gZ3Hg8yJWj",
        "outputId": "93b13aa3-5c3d-49c8-84dd-ff5206da472a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['en'],\n",
            "    num_rows: 1998515\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_from_disk\n",
        "dataset = load_from_disk(\"data_pubmed\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XvxuVHyyJWq",
        "outputId": "b1d88be3-1a00-4d85-ac54-ada849e04565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['en'],\n",
            "        num_rows: 1798663\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['en'],\n",
            "        num_rows: 199852\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTjt04qoyJWr",
        "outputId": "5ad5e427-9323-49c2-9bb5-da0e50a369fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'en': 'Hypophosphatasia (HPP) is a congenital skeletal disease. Impairment of bone mineralization and seizures are due to a deficiency of tissue-nonspecific alkaline phosphatase (TNAP). Enzyme replacement therapy (ERT) is available as a highly successful treatment for pediatric-onset HPP. However, the potential for prenatal ERT has not been fully investigated to date. In this study, we assessed outcomes and maternal safety using a combinational approach with prenatal and postnatal administration of recombinant TNAP in Akp2  mice as a model of infantile HPP. For the prenatal ERT, we administered subcutaneous injections of recombinant TNAP to pregnant mice from embryonic day 11.5-14.5 until delivery, and then sequentially to Akp2  pups from birth to day 18. For the postnatal ERT, we injected Akp2  pups from birth until day 18. Prenatal ERT did not cause any ectopic mineralization in heterozygous maternal mice. Both prenatal and postnatal ERT preserved growth, survival rate and improved bone calcification in Akp2  mice. However, the effects of additional prenatal treatment to newborn mice appeared to be minimal, and the difference between prenatal and postnatal ERT was subtle. Further improvement of the prenatal ERT schedule and long-term observation will be required. The present paper sets a standard for such future studies.'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbzczoixyJWs"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO413aIsyJWx"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"google-bert/bert-base-uncased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dciutUjLyJWy",
        "outputId": "5ccc6990-083b-42fa-b9b0-9b50c4b1d05f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\risuser\\.conda\\envs\\text\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJFKaG8byJWz"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# token_lengths = [\n",
        "#     len(tokenizer(\" \".join(example[\"en\"]), truncation=True, max_length=512)[\"input_ids\"])\n",
        "#     for example in dataset\n",
        "# ]\n",
        "\n",
        "\n",
        "# # Statistik ringkasan\n",
        "# print(f\"Min token: {min(token_lengths)}\")\n",
        "# print(f\"Max token: {max(token_lengths)}\")\n",
        "# print(f\"Mean token: {sum(token_lengths) / len(token_lengths):.2f}\")\n",
        "\n",
        "# # Plot histogram\n",
        "# plt.figure(figsize=(8, 5))\n",
        "# plt.hist(token_lengths, bins=20, color='green', edgecolor=\"black\", alpha=0.7)\n",
        "# plt.xlabel(\"Jumlah Token\")\n",
        "# plt.ylabel(\"Frekuensi\")\n",
        "# plt.title(\"Distribusi Panjang Teks dalam Dataset (Berdasarkan Token BERT)\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWHb-m3iyJW0"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"en\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0fecb8da04a04178bb671987738005b4",
            "a365e13fb4644bdd95d99a20fcf47838"
          ]
        },
        "id": "ruBTorEFyJW7",
        "outputId": "7cde17b3-46ac-42d8-e5ae-a7e551b6dd92"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fecb8da04a04178bb671987738005b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1798663 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a365e13fb4644bdd95d99a20fcf47838",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/199852 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 1798663\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 199852\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "tokenized_data = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    # num_proc=4,\n",
        "    remove_columns=dataset['train'].column_names,\n",
        ")\n",
        "\n",
        "print(tokenized_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft6MG8l8yJW8"
      },
      "outputs": [],
      "source": [
        "block_size = 128\n",
        "\n",
        "\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
        "    # customize this part to your needs.\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "    # Split by chunks of block_size.\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "19661100ebc34e0dbb3ad2832b0f79af",
            "6fb6ce2ced2d427f9716232d43c7490d"
          ]
        },
        "id": "b02I4w9TyJW9",
        "outputId": "19ff00e0-e3f1-4b54-e564-47103cfa8a4d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19661100ebc34e0dbb3ad2832b0f79af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1798663 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fb6ce2ced2d427f9716232d43c7490d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/199852 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lm_dataset = tokenized_data.map(group_texts, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG5s47gCyJXE",
        "outputId": "faa2b5a7-4ef0-4dad-8913-32dbc831d0dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 3690754\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 409695\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(lm_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a34948f00b494469ae7beefd0a95a181",
            "4f0e5bccc94e46149f69eeccbf972697"
          ]
        },
        "id": "3JlhjYA8yJXF",
        "outputId": "1a2eff2e-fc44-44aa-f4ed-bf6310aae8f8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a34948f00b494469ae7beefd0a95a181",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/6 shards):   0%|          | 0/3690754 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f0e5bccc94e46149f69eeccbf972697",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/409695 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# lm_dataset.save_to_disk(\"data_pubmed_BERT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rTYJzbZyJXG"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSIUxgG5yJXH"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "lm_dataset = load_from_disk(\"data_pubmed_BERT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlLUVCI5yJXN",
        "outputId": "e5470da9-456f-4505-babc-a5bc39d035d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 3690754\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 409695\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(lm_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-m3FB5CyJXO",
        "outputId": "4c853c26-19e2-45ad-e9fb-d3d54159b5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3775, 6779, 1010, 2348, 2023, 3921, 2003, 2025, 2109, 18228, 2012, 2556, 1025, 3572, 1997, 26721, 1011, 21183, 24226, 2331, 2064, 2022, 2641, 1037, 7070, 3120, 1997, 2592, 2008, 3791, 2582, 3086, 1012, 4117, 1010, 1996, 2682, 2093, 3210, 1997, 2470, 2089, 6011, 13318, 1010, 2021, 1996, 2640, 1997, 1037, 7721, 2470, 2622, 2052, 2342, 2000, 2022, 8971, 5362, 1012, 12020, 2005, 9740, 1997, 1996, 14404, 1997, 22935, 15451, 14192, 10708, 2024, 2988, 1012, 2083, 3768, 1997, 3716, 1997, 28102, 3012, 1010, 2012, 2556, 1010, 2069, 3905, 9740, 2089, 2022, 2825, 1998, 6516, 17210, 3086, 1012, 2174, 1010, 2045, 3544, 2000, 2022, 2053, 9347, 2005, 16030, 3653, 1011, 17489, 11326, 5852, 2005, 27480, 2540, 4295, 1999, 2019, 4895, 11246, 22471, 2098, 2313, 1012, 102, 101, 2057, 2556, 3350]\n"
          ]
        }
      ],
      "source": [
        "ids = lm_dataset['train']['input_ids'][104212]\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcpWI-ooyJXO",
        "outputId": "1266b277-4f02-43ca-f9ef-6a820e70551e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL97ueXJyJXV"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz8QSGHbyJXW"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamWeightDecay\n",
        "\n",
        "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHgt8eeXyJXX",
        "outputId": "f490761a-0d3a-4a09-82ce-13be85ac7653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
            "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070, compute capability 8.9\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOwE6EEmyJXX",
        "outputId": "7a1629ca-7d3e-42e4-9d19-690f78e9e2dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\risuser\\.conda\\envs\\text\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "All PyTorch model weights were used when initializing TFBertForMaskedLM.\n",
            "\n",
            "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForMaskedLM\n",
        "\n",
        "model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T8d9zNPyJXe",
        "outputId": "f28b1d5f-2fd3-48f7-a1ad-c6f06e95e3b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Policy \"mixed_float16\">\n"
          ]
        }
      ],
      "source": [
        "print(model.dtype_policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m25mnI7UyJXe",
        "outputId": "2c8668c3-b594-4f45-d8fe-3b07ff5da90e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    lm_dataset[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=64,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_test_set = model.prepare_tf_dataset(\n",
        "    lm_dataset[\"test\"],\n",
        "    shuffle=False,\n",
        "    batch_size=64,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZ4k6zANyJXf"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer)  # No loss argument!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ygZc-FbyJXi",
        "outputId": "fc4fa153-f44f-4b34-d0cc-97a2859125aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_masked_lm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108891648 \n",
            "                                                                 \n",
            " mlm___cls (TFBertMLMHead)   multiple                  24459834  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,514,298\n",
            "Trainable params: 109,514,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz7MMSLByJXj"
      },
      "source": [
        "## Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3gf-0bmyJXk",
        "outputId": "47e402be-0ebd-47cb-cc14-16a9074ef1d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\risuser\\.conda\\envs\\text\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/Indahgalaputri/PubMedAbstract2M-BERT into local empty directory.\n"
          ]
        }
      ],
      "source": [
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "\n",
        "hub_callback = PushToHubCallback(\n",
        "    output_dir=\"PubMedAbstract2M-BERT\",\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IljkCaiByJXl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "class HistoryCSVAppendCallback(Callback):\n",
        "    def __init__(self, filepath):\n",
        "        super(HistoryCSVAppendCallback, self).__init__()\n",
        "        self.filepath = filepath\n",
        "        self.first_epoch = not os.path.exists(filepath)  # Check if file exists\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Convert logs to a pandas DataFrame\n",
        "        epoch_history = pd.DataFrame(logs, index=[epoch])\n",
        "\n",
        "        # If file doesn't exist, create it with the header, otherwise append\n",
        "        if self.first_epoch:\n",
        "            epoch_history.to_csv(self.filepath, mode='w', header=True)\n",
        "            self.first_epoch = False\n",
        "        else:\n",
        "            epoch_history.to_csv(self.filepath, mode='a', header=False)\n",
        "\n",
        "# Define file paths for saving model and history\n",
        "history_filepath = 'history_preOrcontinous_training.csv'\n",
        "\n",
        "history_callback = HistoryCSVAppendCallback(filepath=history_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCOW08HfyJXn"
      },
      "outputs": [],
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=2,\n",
        "    restore_best_weights=True,\n",
        "    mode=\"min\",\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K0AV7ClyJXn"
      },
      "outputs": [],
      "source": [
        "callback = [early_stopping, hub_callback, history_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24o6p0giyJXo",
        "outputId": "e02347ad-bc40-4555-c83d-0d485f7803be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "57668/57668 [==============================] - 20953s 363ms/step - loss: 1.4573 - val_loss: 1.2585\n",
            "Epoch 2/5\n",
            "57668/57668 [==============================] - 20965s 364ms/step - loss: 1.2887 - val_loss: 1.1766\n",
            "Epoch 3/5\n",
            "57668/57668 [==============================] - 20984s 364ms/step - loss: 1.2259 - val_loss: 1.1367\n",
            "Epoch 4/5\n",
            "57668/57668 [==============================] - 21008s 364ms/step - loss: 1.1877 - val_loss: 1.1087\n",
            "Epoch 5/5\n",
            "57668/57668 [==============================] - 20969s 364ms/step - loss: 1.1605 - val_loss: 1.0874\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=5, callbacks=callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddoAO58CyJYF",
        "outputId": "910c74eb-6292-4819-8acd-8925c26dea67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6402/6402 [==============================] - 819s 128ms/step - loss: 1.0867\n",
            "Perplexity: 2.9644\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# take loss\n",
        "eval_loss = model.evaluate(tf_test_set)  # Loss per token\n",
        "\n",
        "# Count perplexity\n",
        "perplexity = np.exp(eval_loss)\n",
        "print(f\"Perplexity: {perplexity:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
